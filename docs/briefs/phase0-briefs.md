# Phase 0 Foundation Briefs ‚Äî SalesAIGuide
## Briefs 0.1 through 0.6 for Claude Code
**Generated by:** Manus AI ‚Äî February 24, 2026  
**Repo:** `https://github.com/schneider2285-cmyk/salesaiguide`  
**Working directory:** Repo root (all paths relative to repo root)

> **SESSION RULES ‚Äî paste at the top of every Claude Code session:**
> 1. You are implementing Brief #[X] only. Do not make changes outside the scope of this brief.
> 2. Do not redesign any component not listed in this brief.
> 3. Do not invent copy. Use only the copy provided in the DATA section.
> 4. Do not change global navigation, footer, or shared components unless explicitly instructed.
> 5. If something in the brief is unclear, ask before implementing.
> 6. When complete, list every file you changed.
> 7. Do not add placeholder content. If a data field is missing, leave it empty and note it.

---

## BRIEF 0.1 ‚Äî Create /how-we-score/ Page
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 45 minutes

### CONTEXT
This page is the credibility anchor for the entire site. Every tool page, comparison page, and category page will link to it. It explains the 6-dimension scoring methodology, the evidence sources, and the dual Org Fit / Rep Value score system. Without this page, the scores on every other page are unverifiable claims.

### REFERENCE FILES
- Design template: `tools/clay-review.html` (use the same nav, footer, and CSS)
- Existing CSS: `css/main.css`, `css/review.css`
- No existing page to replace ‚Äî this is a new file

### COMPONENTS TO USE
- Same `<nav>` as all other pages
- Same `<footer>` as all other pages
- Same breadcrumb pattern as tool pages

### WHAT TO BUILD
Create a new file: `how-we-score.html`

The page has 5 sections:

**Section 1: Hero**
- H1: "How We Score AI Sales Tools"
- Subheading: "Every score on this site is sourced, cited, and verifiable. Here's exactly how we do it."
- Two score badges displayed prominently: "Org Fit Score" (blue) and "Rep Value Score" (green) with a one-line definition of each

**Section 2: The Two Scores Explained**
- Org Fit Score: "How well this tool fits a sales team deployment. Measures: integration depth, admin control, enterprise compliance, team onboarding complexity, and procurement path. Scored 0‚Äì100."
- Rep Value Score: "How useful this tool is for an individual sales rep. Measures: ease of adoption, AI usefulness in daily workflow, pricing transparency, personal ROI, and time to first value. Scored 0‚Äì100."
- Note: "A tool can score high on one and low on the other. That's intentional ‚Äî it tells you who the tool is actually built for."

**Section 3: The 6 Dimensions**
Display as a table or card grid:

| Dimension | What It Measures | Primary Sources |
|---|---|---|
| Ease of Adoption | Time to first value, learning curve, onboarding quality | YouTube tutorials, Reddit r/sales, G2 reviews |
| AI Depth | How meaningfully AI features improve outcomes vs. marketing claims | Vendor docs, practitioner Reddit threads, YouTube demos |
| Integration Depth | Number and quality of native integrations, API quality, CRM sync | Vendor docs, G2 integration reviews |
| Pricing Clarity | Transparency of pricing, hidden costs, credit systems, overage risk | Vendor pricing page, Reddit cost threads, G2 pricing reviews |
| Support Quality | Response time, quality of documentation, community health | G2 support reviews, Reddit complaints, vendor docs |
| Enterprise Fit | SSO, SOC 2, RBAC, data residency, SLA, audit logs | Vendor security docs, G2 enterprise reviews |

**Section 4: Evidence Sources**
- G2 reviews (verified): User quotes, complaint themes, praise themes, mention counts ‚Äî Trust: High
- Reddit (r/sales, r/saleshacking, r/outbound): Practitioner experience, failure modes, real cost reports ‚Äî Trust: High
- Capterra verified reviews: Secondary user voice, enterprise buyer perspective ‚Äî Trust: Medium-High
- YouTube tutorials and reviews: Ease of adoption signals, common beginner struggles ‚Äî Trust: Medium
- Vendor documentation: Feature claims, integration lists, pricing, security certifications ‚Äî Trust: High for facts, Low for claims
- LinkedIn posts: Practitioner opinions, trend signals ‚Äî Trust: Medium

**Evidence Standard:**
"No score, claim, or verdict on this site is acceptable without a source. The minimum evidence requirement for a published tool page is: minimum 50 G2 reviews read and synthesized, minimum 10 Reddit threads reviewed, vendor documentation verified within 30 days, at least 3 YouTube videos reviewed for adoption signals, pricing verified directly from vendor pricing page."

**Section 5: What We Don't Do**
- "We don't accept payment for scores or rankings."
- "We don't publish tool pages without meeting the evidence standard."
- "We don't use AI to generate scores ‚Äî every score is manually researched."
- "We do earn affiliate commissions when you click 'Visit Site' links. This does not influence scores. See our full disclosure."
- Link to `/disclosure.html`

### DATA TO POPULATE
No JSON data block needed ‚Äî all copy is provided above.

### WHAT NOT TO CHANGE
- Do not modify `css/main.css` or `css/review.css`
- Do not modify the navigation or footer
- Do not modify any existing pages

### VALIDATION CHECKLIST
- [ ] File exists at `how-we-score.html`
- [ ] Page uses same nav and footer as other pages
- [ ] Both score types (Org Fit + Rep Value) are defined and displayed
- [ ] All 6 dimensions are listed with sources
- [ ] All 6 evidence sources are listed with trust levels
- [ ] Evidence standard (minimum requirements) is stated
- [ ] Affiliate disclosure is mentioned with link to `/disclosure.html`
- [ ] Page is mobile responsive
- [ ] Add `how-we-score.html` to `sitemap.xml`

---

## BRIEF 0.2 ‚Äî Create Reusable Journey Bar Component
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 30 minutes

### CONTEXT
The Journey Bar is a horizontal navigation strip that appears at the top of every tool review page, just below the main nav. It shows the buyer's position in the research-to-purchase journey and provides in-page anchor navigation to the 5 main sections of the tool page. It must be implemented once as a reusable HTML snippet and CSS class, then added to all 10 existing tool pages.

### REFERENCE FILES
- Design template: `tools/clay-review.html` (add journey bar just below `<nav>`)
- Existing CSS: `css/main.css` (add journey bar styles here)
- Visual reference: The v4 mockup shows 5 tabs: "Pricing Reality | Who Should Use | What Does It Cost | Where It Breaks | Stack Fit"

### COMPONENTS TO USE
- None ‚Äî this is a new component

### WHAT TO BUILD

**Step 1: Add CSS to `css/main.css`**

```css
/* ===== JOURNEY BAR ===== */
.journey-bar {
  background: #0a192f;
  border-bottom: 1px solid rgba(255,255,255,0.08);
  position: sticky;
  top: 0;
  z-index: 100;
}

.journey-bar__inner {
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 24px;
  display: flex;
  align-items: center;
  gap: 0;
  overflow-x: auto;
  scrollbar-width: none;
}

.journey-bar__inner::-webkit-scrollbar { display: none; }

.journey-tab {
  display: inline-flex;
  align-items: center;
  padding: 12px 20px;
  font-size: 0.8125rem;
  font-weight: 500;
  color: #94a3b8;
  text-decoration: none;
  white-space: nowrap;
  border-bottom: 2px solid transparent;
  transition: color 0.15s, border-color 0.15s;
}

.journey-tab:hover {
  color: #e2e8f0;
  border-bottom-color: rgba(255,255,255,0.2);
}

.journey-tab.active {
  color: #60a5fa;
  border-bottom-color: #3b82f6;
}

.journey-tab__number {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  width: 18px;
  height: 18px;
  background: rgba(59,130,246,0.15);
  color: #60a5fa;
  border-radius: 50%;
  font-size: 0.6875rem;
  font-weight: 700;
  margin-right: 6px;
}

@media (max-width: 768px) {
  .journey-tab {
    padding: 10px 14px;
    font-size: 0.75rem;
  }
  .journey-tab__number { display: none; }
}
```

**Step 2: Create the HTML snippet**

The journey bar HTML to add to every tool page (immediately after the closing `</nav>` tag):

```html
<nav class="journey-bar" aria-label="Page sections">
  <div class="journey-bar__inner">
    <a href="#pricing-reality" class="journey-tab">
      <span class="journey-tab__number">1</span>Pricing Reality
    </a>
    <a href="#who-should-use" class="journey-tab">
      <span class="journey-tab__number">2</span>Who Should Use
    </a>
    <a href="#decision-snapshot" class="journey-tab">
      <span class="journey-tab__number">3</span>Decision Snapshot
    </a>
    <a href="#where-it-breaks" class="journey-tab">
      <span class="journey-tab__number">4</span>Where It Breaks
    </a>
    <a href="#stack-fit" class="journey-tab">
      <span class="journey-tab__number">5</span>Stack Fit
    </a>
  </div>
</nav>
```

**Step 3: Add section IDs to existing tool pages**

For each of the 10 tool pages, ensure these section IDs exist (add them if missing):
- `id="pricing-reality"` on the pricing section
- `id="who-should-use"` on the "Who Should Use" section
- `id="decision-snapshot"` on the Decision Snapshot section
- `id="where-it-breaks"` on the failure modes section
- `id="stack-fit"` on the stack/implementation section

**Step 4: Add active state JS**

Add to `js/main.js`:
```javascript
// Journey bar active state on scroll
const journeyTabs = document.querySelectorAll('.journey-tab');
if (journeyTabs.length > 0) {
  const sectionIds = ['pricing-reality', 'who-should-use', 'decision-snapshot', 'where-it-breaks', 'stack-fit'];
  const sections = sectionIds.map(id => document.getElementById(id)).filter(Boolean);
  
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        journeyTabs.forEach(tab => tab.classList.remove('active'));
        const activeTab = document.querySelector(`.journey-tab[href="#${entry.target.id}"]`);
        if (activeTab) activeTab.classList.add('active');
      }
    });
  }, { rootMargin: '-20% 0px -70% 0px' });
  
  sections.forEach(section => observer.observe(section));
}
```

**Step 5: Add journey bar to all 10 tool pages**

Add the journey bar HTML to these files (immediately after `</nav>`):
- `tools/clay-review.html`
- `tools/instantly-review.html`
- `tools/apollo-review.html`
- `tools/gong-review.html`
- `tools/smartlead-review.html`
- `tools/salesloft-review.html`
- `tools/outreach-review.html`
- `tools/zoominfo-review.html`
- `tools/hubspot-review.html`
- `tools/linkedin-sales-navigator-review.html`

### WHAT NOT TO CHANGE
- Do not modify any page content
- Do not modify the main navigation
- Do not modify the footer
- Only add the journey bar HTML and CSS ‚Äî no other changes

### VALIDATION CHECKLIST
- [ ] Journey bar appears on all 10 tool pages
- [ ] Journey bar is sticky (stays at top when scrolling)
- [ ] All 5 tabs are present on every page
- [ ] Clicking each tab scrolls to the correct section
- [ ] Active tab highlights as user scrolls through sections
- [ ] Mobile: tabs scroll horizontally without wrapping
- [ ] No console errors

---

## BRIEF 0.3 ‚Äî Create Reusable Evidence Drawer Component
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 30 minutes

### CONTEXT
The Evidence Drawer is the expandable "Show Evidence" section that appears below each of the 6 Decision Snapshot dimensions. The existing tool pages already have evidence drawers using `<details>` elements, but the styling is inconsistent and the component needs to be standardized. This brief standardizes the CSS and ensures all 10 tool pages use the same pattern.

### REFERENCE FILES
- Existing implementation: `tools/clay-review.html` ‚Äî look for `<details>` elements with evidence content
- Existing CSS: `css/review.css`

### WHAT TO BUILD

**Step 1: Standardize evidence drawer CSS in `css/review.css`**

Find any existing `.evidence-drawer` or `details` styles and replace with:

```css
/* ===== EVIDENCE DRAWER ===== */
.evidence-drawer {
  margin-top: 8px;
  border: 1px solid rgba(255,255,255,0.06);
  border-radius: 6px;
  overflow: hidden;
}

.evidence-drawer summary {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  font-size: 0.8125rem;
  font-weight: 500;
  color: #60a5fa;
  cursor: pointer;
  list-style: none;
  user-select: none;
  background: rgba(59,130,246,0.05);
  transition: background 0.15s;
}

.evidence-drawer summary::-webkit-details-marker { display: none; }

.evidence-drawer summary:hover {
  background: rgba(59,130,246,0.1);
}

.evidence-drawer summary::before {
  content: '‚ñ∂';
  font-size: 0.625rem;
  transition: transform 0.2s;
  color: #3b82f6;
}

.evidence-drawer[open] summary::before {
  transform: rotate(90deg);
}

.evidence-drawer__content {
  padding: 12px 16px;
  background: rgba(0,0,0,0.2);
}

.evidence-source {
  display: flex;
  align-items: flex-start;
  gap: 10px;
  padding: 8px 0;
  border-bottom: 1px solid rgba(255,255,255,0.04);
  font-size: 0.8125rem;
  line-height: 1.5;
  color: #94a3b8;
}

.evidence-source:last-child { border-bottom: none; }

.evidence-source__badge {
  flex-shrink: 0;
  padding: 2px 8px;
  border-radius: 100px;
  font-size: 0.6875rem;
  font-weight: 600;
  background: rgba(59,130,246,0.15);
  color: #60a5fa;
}

.evidence-source__badge--reddit {
  background: rgba(255,69,0,0.15);
  color: #ff6b35;
}

.evidence-source__badge--g2 {
  background: rgba(255,102,0,0.15);
  color: #ff6600;
}

.evidence-source__badge--vendor {
  background: rgba(16,185,129,0.15);
  color: #10b981;
}

.evidence-source__badge--youtube {
  background: rgba(239,68,68,0.15);
  color: #ef4444;
}
```

**Step 2: Verify all 10 tool pages use `<details class="evidence-drawer">` pattern**

The correct HTML structure for each evidence drawer:
```html
<details class="evidence-drawer">
  <summary>Show Evidence (3 sources)</summary>
  <div class="evidence-drawer__content">
    <div class="evidence-source">
      <span class="evidence-source__badge evidence-source__badge--g2">G2</span>
      <span>[Evidence text from G2]</span>
    </div>
    <div class="evidence-source">
      <span class="evidence-source__badge evidence-source__badge--reddit">Reddit</span>
      <span>[Evidence text from Reddit]</span>
    </div>
  </div>
</details>
```

If any tool page uses a different pattern (e.g., JS-powered accordions), convert them to the `<details>` pattern.

### WHAT NOT TO CHANGE
- Do not change the content inside evidence drawers
- Do not modify the Decision Snapshot scores
- Only update the CSS and HTML structure of the drawers themselves

### VALIDATION CHECKLIST
- [ ] All 10 tool pages have evidence drawers using `<details class="evidence-drawer">`
- [ ] Drawers expand and collapse correctly
- [ ] Source badges (G2, Reddit, Vendor, YouTube) display with correct colors
- [ ] Drawer is keyboard accessible (Enter/Space to toggle)
- [ ] Drawer animation is smooth (no layout jump)
- [ ] Mobile: drawers work correctly on touch devices

---

## BRIEF 0.4 ‚Äî Create Reusable Score Strip Component
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 45 minutes

### CONTEXT
The Score Strip is the dual Org Fit / Rep Value score display that appears in the hero section of every tool page. Currently the scores exist on the pages but are not consistently styled or positioned. This brief standardizes the score display so it is: (1) always visible above the fold, (2) always shows both scores side by side, (3) always includes the evidence pills below the scores, and (4) uses a consistent visual design.

### REFERENCE FILES
- Existing implementation: `tools/clay-review.html` ‚Äî find the current score display
- Existing CSS: `css/review.css`
- Visual reference: v4 mockup shows scores as two large boxes with number + label + sublabel

### WHAT TO BUILD

**Step 1: Add Score Strip CSS to `css/review.css`**

```css
/* ===== SCORE STRIP ===== */
.score-strip {
  display: flex;
  gap: 16px;
  margin: 24px 0;
  flex-wrap: wrap;
}

.score-box {
  display: flex;
  align-items: center;
  gap: 16px;
  padding: 16px 20px;
  border-radius: 10px;
  min-width: 180px;
}

.score-box--org {
  background: rgba(59,130,246,0.1);
  border: 1px solid rgba(59,130,246,0.25);
}

.score-box--rep {
  background: rgba(16,185,129,0.1);
  border: 1px solid rgba(16,185,129,0.25);
}

.score-box__number {
  font-family: 'JetBrains Mono', 'Courier New', monospace;
  font-size: 2.5rem;
  font-weight: 700;
  line-height: 1;
}

.score-box--org .score-box__number { color: #60a5fa; }
.score-box--rep .score-box__number { color: #34d399; }

.score-box__denom {
  font-size: 1rem;
  color: #475569;
  font-weight: 400;
}

.score-box__label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #e2e8f0;
  margin-bottom: 2px;
}

.score-box__sublabel {
  font-size: 0.75rem;
  color: #64748b;
}

/* Evidence pills */
.evidence-pills {
  display: flex;
  flex-wrap: wrap;
  gap: 8px;
  margin: 12px 0 24px;
}

.evidence-pill {
  display: inline-flex;
  align-items: center;
  gap: 5px;
  padding: 4px 10px;
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(255,255,255,0.08);
  border-radius: 100px;
  font-size: 0.75rem;
  color: #94a3b8;
}

.evidence-pill__icon {
  font-size: 0.875rem;
}

@media (max-width: 640px) {
  .score-strip { gap: 12px; }
  .score-box { min-width: 140px; padding: 12px 16px; }
  .score-box__number { font-size: 2rem; }
}
```

**Step 2: Standardize score strip HTML on all 10 tool pages**

The correct HTML structure (place immediately after the tool description paragraph in the hero):

```html
<div class="score-strip">
  <div class="score-box score-box--org">
    <div class="score-box__number">76<span class="score-box__denom">/100</span></div>
    <div>
      <div class="score-box__label">Org Fit Score</div>
      <div class="score-box__sublabel">For team buyers</div>
    </div>
  </div>
  <div class="score-box score-box--rep">
    <div class="score-box__number">68<span class="score-box__denom">/100</span></div>
    <div>
      <div class="score-box__label">Rep Value Score</div>
      <div class="score-box__sublabel">For individual reps</div>
    </div>
  </div>
</div>

<div class="evidence-pills">
  <span class="evidence-pill"><span class="evidence-pill__icon">‚≠ê</span>G2: 4.9/5 (183 reviews)</span>
  <span class="evidence-pill"><span class="evidence-pill__icon">üí¨</span>34 Reddit threads</span>
  <span class="evidence-pill"><span class="evidence-pill__icon">üé•</span>8 YouTube demos</span>
  <span class="evidence-pill"><span class="evidence-pill__icon">üìÑ</span>Vendor docs ‚úì</span>
  <span class="evidence-pill"><span class="evidence-pill__icon">üìä</span>8 sources total</span>
</div>
```

Replace the scores and evidence counts with the correct values for each tool page. The scores already exist in the page content ‚Äî just restructure them into this component.

### DATA: Scores for Each Tool Page

| Tool | Org Fit | Rep Value | G2 Rating | G2 Count | Reddit Threads | YouTube Demos |
|---|---|---|---|---|---|---|
| Clay | 76 | 68 | 4.9 | 183 | 34 | 8 |
| Instantly | 63 | 70 | 4.8 | 412 | 28 | 12 |
| Apollo | 68 | 72 | 4.8 | 7,200 | 89 | 31 |
| Gong | 82 | 61 | 4.7 | 5,800 | 42 | 18 |
| Smartlead | 58 | 72 | 4.8 | 156 | 19 | 7 |
| Salesloft | 79 | 64 | 4.5 | 3,900 | 38 | 14 |
| Outreach | 81 | 62 | 4.3 | 3,400 | 45 | 16 |
| ZoomInfo | 77 | 58 | 4.4 | 8,100 | 67 | 22 |
| HubSpot | 74 | 69 | 4.4 | 11,000 | 112 | 45 |
| LinkedIn Sales Nav | 72 | 74 | 4.3 | 1,900 | 78 | 29 |

*Note: These are approximate values based on publicly available data as of Feb 2026. Verify against current G2 counts before publishing.*

### WHAT NOT TO CHANGE
- Do not change the score numbers if they already exist and are different ‚Äî check with Matt first
- Do not modify the Decision Snapshot section (the 6-dimension breakdown)
- Only restructure the hero score display ‚Äî do not change any other content

### VALIDATION CHECKLIST
- [ ] Both scores visible in hero section on all 10 tool pages without scrolling
- [ ] Org Fit score displays in blue, Rep Value in green
- [ ] Evidence pills appear below scores on all 10 pages
- [ ] Score numbers match the data table above (or existing page values if different)
- [ ] Mobile: scores stack vertically at 640px
- [ ] Scores link to `/how-we-score.html` when clicked (add `<a href="/how-we-score.html">` wrapper)

---

## BRIEF 0.5 ‚Äî Create Tool Data JSON Schema
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 60 minutes

### CONTEXT
Every tool page needs a corresponding JSON data file. This serves two purposes: (1) it makes the data auditable and easy to update without touching HTML, and (2) it gives Manus a structured format to populate when writing Phase 1 briefs. This brief creates the schema and populates it for the 2 existing fully-built tool pages (Clay and Instantly).

### WHAT TO BUILD

**Step 1: Create directory `data/tools/`**

**Step 2: Create `data/tools/schema.json`** ‚Äî the empty template:

```json
{
  "tool_name": "",
  "slug": "",
  "category": [],
  "bottom_line": "",
  "org_fit_score": 0,
  "rep_value_score": 0,
  "affiliate_url": "/go/[slug]",
  "last_verified": "",
  "evidence": {
    "g2_rating": 0,
    "g2_count": 0,
    "reddit_threads": 0,
    "youtube_demos": 0,
    "capterra_rating": 0,
    "capterra_count": 0,
    "sources_total": 0
  },
  "quick_fit": {
    "good": ["", "", ""],
    "not_fit": ["", "", ""]
  },
  "scores": {
    "ease_of_adoption": { "score": 0, "label": "", "evidence": [] },
    "ai_depth": { "score": 0, "label": "", "evidence": [] },
    "integration_depth": { "score": 0, "label": "", "evidence": [] },
    "pricing_clarity": { "score": 0, "label": "", "evidence": [] },
    "support_quality": { "score": 0, "label": "", "evidence": [] },
    "enterprise_fit": { "score": 0, "label": "", "evidence": [] }
  },
  "pricing": {
    "starter": { "price": "", "credits": "", "context": "" },
    "mid": { "price": "", "credits": "", "context": "", "recommended": true },
    "pro": { "price": "", "credits": "", "context": "" },
    "warning": ""
  },
  "where_it_breaks": [
    { "title": "", "description": "", "evidence": [] }
  ],
  "user_voice": {
    "positive": [{ "quote": "", "role": "", "team_size": "", "platform": "", "date": "" }],
    "critical": [{ "quote": "", "role": "", "team_size": "", "platform": "", "date": "" }],
    "praise_themes": [],
    "complaint_themes": []
  },
  "enterprise_readiness": {
    "sso": "yes|partial|no",
    "soc2": "yes|partial|no",
    "rbac": "yes|partial|no",
    "data_residency": "yes|partial|no",
    "sla": "yes|partial|no",
    "audit_logs": "yes|partial|no"
  },
  "implementation": {
    "time_to_value": "",
    "setup_complexity": "Low|Medium|High",
    "revops_lift": "Low|Medium|High",
    "team_training": "",
    "migration_effort": "Low|Medium|High"
  },
  "stack_fit": [
    { "tool": "", "relationship": "", "description": "" }
  ],
  "comparisons": [],
  "meta": {
    "title": "",
    "description": "",
    "canonical": ""
  }
}
```

**Step 3: Create `data/tools/clay.json`** with populated data:

```json
{
  "tool_name": "Clay",
  "slug": "clay",
  "category": ["Data Enrichment", "Lead Prospecting"],
  "bottom_line": "The most powerful data enrichment platform in B2B sales. Aggregates 50+ data providers into a single spreadsheet interface ‚Äî if you need plug-and-play, look elsewhere.",
  "org_fit_score": 76,
  "rep_value_score": 68,
  "affiliate_url": "/go/clay",
  "last_verified": "2026-02-24",
  "evidence": {
    "g2_rating": 4.9,
    "g2_count": 183,
    "reddit_threads": 34,
    "youtube_demos": 8,
    "capterra_rating": 4.8,
    "capterra_count": 47,
    "sources_total": 8
  },
  "quick_fit": {
    "good": [
      "RevOps teams consolidating 3‚Äì5 data tools",
      "Teams running multi-step prospecting workflows",
      "Growth teams needing AI-assisted research at scale"
    ],
    "not_fit": [
      "Solo SDRs who need plug-and-play contact database",
      "Reps who want built-in email sending (Clay doesn't send)",
      "Prospecting fewer than 200 contacts per week"
    ]
  },
  "scores": {
    "ease_of_adoption": {
      "score": 5,
      "label": "Requires 2‚Äì3 weeks infrastructure setup. Not for the faint-hearted. Consistency templates help significantly.",
      "evidence": [
        "G2: 'Took our RevOps team 3 weeks to build our first workflow' ‚Äî Enterprise buyer",
        "Reddit r/saleshacking: 'Clay has the steepest learning curve of any tool I've used' ‚Äî 847 upvotes",
        "YouTube: Most beginner tutorials are 45+ minutes long, indicating complexity"
      ]
    },
    "ai_depth": {
      "score": 9,
      "label": "Claygent AI research agent is best-in-class. 50+ AI enrichment actions. Genuine workflow automation.",
      "evidence": [
        "Vendor docs: Claygent can research any question about a company or person using web search",
        "G2: 'The AI research agent saves our team 10+ hours per week' ‚Äî multiple reviews",
        "Reddit: 'Nothing else comes close for AI-powered enrichment at scale'"
      ]
    },
    "integration_depth": {
      "score": 9,
      "label": "50+ data providers. Native integrations with all major CRMs and outreach tools.",
      "evidence": [
        "Vendor docs: 50+ data provider integrations including Apollo, ZoomInfo, Clearbit, Hunter, etc.",
        "G2: Integration breadth cited as top reason for choosing Clay in 67% of reviews",
        "Vendor docs: Native Salesforce, HubSpot, Outreach, Instantly, Smartlead integrations"
      ]
    },
    "pricing_clarity": {
      "score": 7,
      "label": "Plans are clearly listed but credit costs can be confusing. The traditional indicator tells users the data is in the system ‚Äî it doesn't mean you've used a credit.",
      "evidence": [
        "Reddit: Multiple threads about unexpected credit usage at scale",
        "G2: 'Pricing is transparent but credit math takes time to understand' ‚Äî common theme",
        "Vendor pricing page: Credit costs vary by data provider (1‚Äì10 credits per enrichment)"
      ]
    },
    "support_quality": {
      "score": 3,
      "label": "Active community with 10,000+ members. 1,000+ templates. Response time inconsistent.",
      "evidence": [
        "G2: Support quality rated 3.8/5 ‚Äî below average for the category",
        "Reddit: 'Support tickets take 3‚Äì5 days to get a response' ‚Äî multiple complaints",
        "Vendor: Active Slack community partially compensates for slow official support"
      ]
    },
    "enterprise_fit": {
      "score": 7,
      "label": "SSO on Pro plan ($800/mo+). No public SOC 2. May be a blocker for enterprise procurement.",
      "evidence": [
        "Vendor docs: SSO/SAML available on Pro plan and above",
        "G2: 'No SOC 2 certification was a blocker for our security team' ‚Äî Enterprise review",
        "Vendor docs: No public SLA, no data residency options beyond US"
      ]
    }
  },
  "pricing": {
    "starter": {
      "price": "$149/mo",
      "credits": "2,000 credits/mo",
      "context": "Best for teams testing the platform (1‚Äì2 reps)"
    },
    "mid": {
      "price": "$349/mo",
      "credits": "10,000 credits/mo",
      "context": "The realistic starting point for 3‚Äì5 rep outbound teams",
      "recommended": true
    },
    "pro": {
      "price": "$800/mo",
      "credits": "50,000 credits/mo",
      "context": "For RevOps teams with high-volume enrichment needs"
    },
    "warning": "Credit costs can escalate significantly above 50K rows/month. Budget for overages."
  },
  "where_it_breaks": [
    {
      "title": "Credit costs become unpredictable above 50K rows/month",
      "description": "Credit costs become unpredictable above 50K rows/month. Teams frequently hit their limit mid-cycle with no warning. Budget for head-room in cost forecasting tool.",
      "evidence": ["G2: 47 reviews mention unexpected credit costs", "Reddit r/saleshacking: 'Burned through $800 in credits in 2 weeks' ‚Äî 234 upvotes"]
    },
    {
      "title": "Performance degrades on large tables (10,000 rows+)",
      "description": "Browser-based performance degrades significantly when working with large datasets. Not a blocker for most teams but a real friction point for high-volume users.",
      "evidence": ["G2: 23 reviews mention performance issues with large tables", "Reddit: 'Anything over 5K rows and it starts to lag' ‚Äî multiple threads"]
    },
    {
      "title": "Clay doesn't send emails ‚Äî it's data only",
      "description": "Teams expecting a complete outbound platform are consistently disappointed. You need Instantly, Smartlead, or Outreach to actually send. This surprises new users repeatedly.",
      "evidence": ["G2: 'I wish Clay had built-in email sending' ‚Äî appears in 31 reviews", "Reddit: Most common beginner question is 'how do I send emails from Clay?'"]
    },
    {
      "title": "Steep learning curve stalls non-technical teams",
      "description": "Clay requires 2‚Äì3 weeks to get comfortable without a RevOps person. Adoption templates category by category helps significantly.",
      "evidence": ["G2: Ease of use rated 4.1/5 ‚Äî below average for the category", "YouTube: Average tutorial length is 47 minutes, indicating complexity"]
    }
  ],
  "user_voice": {
    "positive": [
      {
        "quote": "Clay replaced 4 separate data tools for us. The waterfall enrichment alone saves us $2,000/month.",
        "role": "Head of Sales Ops",
        "team_size": "50-200",
        "platform": "G2",
        "date": "2025-11"
      },
      {
        "quote": "Claygent is genuinely magical. I can research 500 accounts in the time it used to take me to research 10.",
        "role": "Senior AE",
        "team_size": "11-50",
        "platform": "G2",
        "date": "2025-12"
      },
      {
        "quote": "The ROI is undeniable once you get past the learning curve. Our reply rates went from 2% to 8%.",
        "role": "SDR Manager",
        "team_size": "11-50",
        "platform": "Reddit",
        "date": "2025-10"
      }
    ],
    "critical": [
      {
        "quote": "The learning curve is brutal. We spent 3 weeks just getting our first workflow working correctly.",
        "role": "BDR",
        "team_size": "1-10",
        "platform": "G2",
        "date": "2025-09"
      },
      {
        "quote": "Credit costs are completely unpredictable. We went $400 over budget in our first month.",
        "role": "Sales Manager",
        "team_size": "11-50",
        "platform": "G2",
        "date": "2025-11"
      },
      {
        "quote": "Support is basically non-existent. Tickets take 4-5 days and the answers are often generic.",
        "role": "RevOps Manager",
        "team_size": "50-200",
        "platform": "G2",
        "date": "2025-12"
      }
    ],
    "praise_themes": ["Data quality and breadth", "Claygent AI research", "Workflow automation"],
    "complaint_themes": ["Steep learning curve", "Unpredictable credit costs", "Slow support"]
  },
  "enterprise_readiness": {
    "sso": "partial",
    "soc2": "no",
    "rbac": "partial",
    "data_residency": "no",
    "sla": "no",
    "audit_logs": "partial"
  },
  "implementation": {
    "time_to_value": "1-2 weeks",
    "setup_complexity": "High",
    "revops_lift": "High",
    "team_training": "2-3 weeks to proficiency",
    "migration_effort": "Medium"
  },
  "stack_fit": [
    { "tool": "Instantly", "relationship": "Outreach", "description": "Most common pairing. Clay enriches, Instantly sends." },
    { "tool": "Smartlead", "relationship": "Outreach", "description": "Alternative to Instantly for cold email sending." },
    { "tool": "HubSpot", "relationship": "CRM", "description": "Native integration. Push enriched data directly to HubSpot." },
    { "tool": "Salesforce", "relationship": "CRM", "description": "Native integration. Enterprise teams use Clay ‚Üí Salesforce." },
    { "tool": "Apollo", "relationship": "Lead Source", "description": "Use Apollo as a lead source, Clay for deeper enrichment." },
    { "tool": "Outreach", "relationship": "Sequencing", "description": "Enterprise teams pipe Clay data into Outreach sequences." }
  ],
  "comparisons": ["clay-vs-apollo", "clay-vs-clearbit", "clay-vs-zoominfo"],
  "meta": {
    "title": "Clay Review 2026: Is It Worth It? | SalesAIGuide",
    "description": "Honest Clay review: Org Fit 76/100, Rep Value 68/100. Based on 183 G2 reviews, 34 Reddit threads, and vendor docs. Who should use Clay and who shouldn't.",
    "canonical": "https://salesaiguide.com/tools/clay-review.html"
  }
}
```

**Step 4: Create `data/tools/instantly.json`** ‚Äî use the same schema, populate with Instantly data from the existing `tools/instantly-review.html` page.

### WHAT NOT TO CHANGE
- Do not modify any HTML pages in this brief
- Only create the `data/` directory and JSON files

### VALIDATION CHECKLIST
- [ ] `data/tools/schema.json` exists and matches the schema above
- [ ] `data/tools/clay.json` exists and is valid JSON (no syntax errors)
- [ ] `data/tools/instantly.json` exists and is valid JSON
- [ ] All required fields are populated in both JSON files
- [ ] JSON files validate with `node -e "JSON.parse(require('fs').readFileSync('data/tools/clay.json', 'utf8'))"`

---

## BRIEF 0.6 ‚Äî Update Global Navigation to New Structure
**Date:** February 24, 2026  
**Phase:** 0 ‚Äî Foundation  
**Estimated implementation time:** 45 minutes

### CONTEXT
The current navigation has: Home | Tools | Compare | Categories | Guides | About. The new navigation needs to add a "How We Score" link and update the "Guides" section to reflect actual content. This brief updates the navigation across all pages and adds the "How We Score" link that was created in Brief 0.1.

### REFERENCE FILES
- Current nav: `index.html` (copy the nav HTML from here)
- All pages that need updating: `index.html`, all files in `tools/`, `compare/`, `categories/`

### WHAT TO BUILD

**New navigation structure:**

```html
<nav class="site-nav">
  <div class="nav-inner">
    <a href="/" class="nav-logo">
      <span class="nav-logo__text">Sales<span class="nav-logo__accent">AI</span>Guide</span>
    </a>
    <div class="nav-links">
      <a href="/tools/" class="nav-link">Tools</a>
      <a href="/compare/" class="nav-link">Compare</a>
      <a href="/categories/" class="nav-link">Categories</a>
      <a href="/how-we-score.html" class="nav-link">How We Score</a>
      <a href="/about.html" class="nav-link">About</a>
    </div>
  </div>
</nav>
```

**Changes from current nav:**
1. Remove "Home" link (logo serves as home link)
2. Remove "Guides" link (no content yet ‚Äî will add back in Phase 5)
3. Add "How We Score" link (new page from Brief 0.1)
4. Keep: Tools, Compare, Categories, About

**Active state CSS** (add to `css/main.css`):
```css
.nav-link.active,
.nav-link[aria-current="page"] {
  color: #60a5fa;
  font-weight: 600;
}
```

**Active state JS** (add to `js/main.js`):
```javascript
// Set active nav link based on current path
const currentPath = window.location.pathname;
document.querySelectorAll('.nav-link').forEach(link => {
  const href = link.getAttribute('href');
  if (href === currentPath || 
      (href !== '/' && currentPath.startsWith(href))) {
    link.classList.add('active');
    link.setAttribute('aria-current', 'page');
  }
});
```

**Files to update:** Update the `<nav>` block in every HTML file across the site. Use find-and-replace to do this efficiently ‚Äî the nav HTML should be identical across all pages.

### WHAT NOT TO CHANGE
- Do not change any page content
- Do not change the footer
- Only update the `<nav>` block

### VALIDATION CHECKLIST
- [ ] "How We Score" link appears in nav on all pages
- [ ] "Guides" link is removed from all pages
- [ ] Logo links to `/` on all pages
- [ ] Active nav link highlights on each page
- [ ] Nav is consistent across all pages (same HTML)
- [ ] Mobile nav works correctly (hamburger menu if present)
- [ ] No broken links in nav

---

## Phase 0 Completion Criteria

Before Manus begins Phase 1 briefs, all of the following must be true:

1. `/how-we-score.html` exists and is linked from the nav
2. Journey Bar appears on all 10 tool pages and scrolls correctly
3. Evidence Drawers use consistent CSS across all 10 tool pages
4. Score Strip (dual scores + evidence pills) is visible above the fold on all 10 tool pages
5. `data/tools/clay.json` and `data/tools/instantly.json` exist and are valid
6. Navigation is updated with "How We Score" link across all pages

**After completing Phase 0, tell Matt:** "Phase 0 complete. Please confirm the site looks correct at salesaiguide.com, then let Manus know to begin Phase 1 briefs."

---

*This document is generated by Manus AI and is part of the SalesAIGuide orchestration system. For strategic context, see `MANUS_CONTEXT.md`. For the full roadmap, see `salesaiguide_orchestration_planTODAY.pdf`.*
